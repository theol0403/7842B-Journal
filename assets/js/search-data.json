{
  
  
  "0": {
    "title": "",
    "content": "404 . Page not found :( . The requested page could not be found. .",
    "url": "https://theol0403.github.io/7842B-Journal/404.html",
    "relUrl": "/404.html"
  }
  ,"1": {
    "title": "Archive",
    "content": "Tower Takover Archive . This is an archive of old entries from last year. A lot of code and concepts is reused in the current year. . . . {% assign posts = site.posts | where: &quot;parent&quot;, &quot;Archive&quot; %} {% for post in posts %} {{ post.title }} - {{ post.date | date: &quot;%B %d, %Y&quot; }} | {% endfor %} .",
    "url": "https://theol0403.github.io/7842B-Journal/archive",
    "relUrl": "/archive"
  }
  ,"2": {
    "title": "Build",
    "content": "Build Journal . I’m Sawyer McClellan, and this is my digital build journal for the 2020/2021 Change Up season! . My primary role on the team is to design and build the robot. I also am the main driver. . This year, we have gone through 3 major iterations of the robot. The relevant features and improvements of each iteration is categorized below: . Robot V1 Robot V2 Robot V3 . . . {% assign posts = site.posts | where: &quot;parent&quot;, &quot;Build&quot; %} {% for post in posts %} {{ post.title }} - {{ post.date | date: &quot;%B %d, %Y&quot; }} | {% endfor %} .",
    "url": "https://theol0403.github.io/7842B-Journal/build",
    "relUrl": "/build"
  }
  ,"3": {
    "title": "Home",
    "content": "7842B Digital Engineering Journal . Welcome to the Digital Engineering Journal for VEX team 7842B in the Change Up season! . We are a two-person team, consisting of: . Theo Lemay - Programmer | Sawyer McClellan - Builder | . This is a joint digital journal, with sections for building and programming. . Programming Journal Build Journal . . Archive . Parts of the code used for the robot is built on previous years work, so relevant journal entries are kept in archive. . Tower Takeover Archive . . . {% for post in site.posts %} {{ post.title }} - {{ post.date | date: &quot;%B %d, %Y&quot; }} | {% endfor %} .",
    "url": "https://theol0403.github.io/7842B-Journal/",
    "relUrl": "/"
  }
  ,"4": {
    "title": "Intake Automation",
    "content": "Intake Automation . {% if page.author %} {{ page.author}} {% endif %} . One of my main roles as programmer is to design and implement robot automation and interaction with driver controls. . My go-to solution for subsystem control is to create a statemachine controller. . . . {% assign posts = site.posts | where: &quot;parent&quot;, &quot;Intake Automation&quot; %} {% for post in posts %} {{ post.title }} - {{ post.date | date: &quot;%B %d, %Y&quot; }} | {% endfor %} .",
    "url": "https://theol0403.github.io/7842B-Journal/programming/intake",
    "relUrl": "/programming/intake"
  }
  ,"5": {
    "title": "Motion Control",
    "content": "Motion Control . {% if page.author %} {{ page.author}} {% endif %} . To execute any autonomous routine, the robot needs movement algorithms. These are functions that use sensors, controllers, and kinematics to move the robot somewhere. . . . {% assign posts = site.posts | where: &quot;parent&quot;, &quot;Motion Control&quot; %} {% for post in posts %} {{ post.title }} - {{ post.date | date: &quot;%B %d, %Y&quot; }} | {% endfor %} .",
    "url": "https://theol0403.github.io/7842B-Journal/programming/motion",
    "relUrl": "/programming/motion"
  }
  ,"6": {
    "title": "Programming",
    "content": "Programming Journal . Hello! I’m Theo Lemay, and this is my digital programming journal for the 2020/2021 Change Up season. . My primary role on the team is to design driver controls, design autonomous motion control algorithms, and design and develop autonomous skills routines. I also assist with building and driving. . This season, I have invested the majority of my time on three major tasks: . Programming Skills . Design and implement a programming skills run that is consistent and fast. | . Programming Skills . Intake Control . Develop an intuitive and versatile driver control scheme for the robot intakes that make it easy to drive. | Implement a statemachine controller that combines driver and sensor input to achieve smooth and intuitive ball handling. | Use sensors to automate features like autopooping, which is the automatic disposal of unwanted balls. | . Intake Control . Motion Control . Develop smooth, repeatable, and powerful motion algorithms, for fast and optimal navigation during autonomous. | Use sensors to improve reliability, like localization, vision seeking, and velocity control. | . Motion Control .",
    "url": "https://theol0403.github.io/7842B-Journal/programming",
    "relUrl": "/programming"
  }
  ,"7": {
    "title": "Skills",
    "content": "Programming Skills . {% if page.author %} {{ page.author}} {% endif %} . I need to find the best programming skills routine. Considerations: . point turns are slow and prone to error | reducing the number of separate motions and optimizing for long, smooth motions is ideal | the locations where the robot can dispose blue balls (poop) must be carefully selected to not collide with other balls | goals can be used to realign the robot | . Template Maps . . . . {% assign posts = site.posts | where: &quot;parent&quot;, &quot;Skills&quot; | reverse %} {% for post in posts %} {{ post.title }} - {{ post.date | date: &quot;%B %d, %Y&quot; }} | {% endfor %} .",
    "url": "https://theol0403.github.io/7842B-Journal/programming/skills",
    "relUrl": "/programming/skills"
  }
  ,"8": {
    "title": "V3 Skills",
    "content": ". New routine | Ambitious Plan | Update Apr 5 | Previously, our routine was only designed to score a maximum of 122 points (out of 126), purposefully excluding 4 of the balls. It looked something like this: . We are only slightly under time, so in order to get the last 4 balls, something needs to be different. Simply modifying the current routine to grab the last 4 balls is not possible. . New routine . Here are a few ways we can shave off time and make it possible to get the last 4 balls: . Robot V3 can intake the blue balls from the center tower rather than needing to poke them out. This can save us about 8 seconds. | Spending less time at each goal and perfecting the shoot/intake timing can save us about 5 seconds. | Adding a hood catapult to the robot can allow us to quickly score our preload, saving us about 3 seconds | Redesigning the entire autonomous to be more efficient, with the last 4 balls in mind, and reducing point turns, can save us about 10 seconds. | . For the last point, the more complex the motions are (driving while turning, complex arcs), the more optimal the routine can be. . One possible routine: . . Where B is the start, E is the end, red is translation, blue is front-facing direction, green is point turns, and light blue is potential “poop” locations. The star is a hood catapult. . In this run, there are 11-12 point turns. . Ambitious Plan . Here is a new ambitious plan which only has 4 point turns! . . Where red is forward, blue is backward, green is strafing, purple is heading, orange is poop locations, and beige is locations for line-sensor alignment. . It requires: . holonomic motion profiling (turning while driving) | consistent velocity following | line sensor adjustment | . As long as I achieve these things in code the routine should be doable. . Update Apr 5 . I drove the autonomous routine and verified that it is in fact possible to execute. Onwards with the plan! .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-04-03/v3-skills/",
    "relUrl": "/2021-04-03/v3-skills/"
  }
  ,"9": {
    "title": "Hood Catapult",
    "content": "We made a hood catapult so that at the beginning of the match when the robot deploys it automatically launches the ball into the goal which saves us time and makes it easier to get the next few balls. . .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-04-02/hood-catapult/",
    "relUrl": "/2021-04-02/hood-catapult/"
  }
  ,"10": {
    "title": "Intake changes",
    "content": "We changed the intake from treads to the new flex wheels so that its able to intake balls out of the center goal. This saves us a lot of time on completing the center goal. . . We also changed it from rotating on a standoff to having a solid motor with the wheels rotating on the axel. Having the motor solid makes the hole intake much more secure. .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-03-29/intake-changes/",
    "relUrl": "/2021-03-29/intake-changes/"
  }
  ,"11": {
    "title": "Roller changes",
    "content": "We changed the middle roller to a bigger size and moved it down because with the new intake design it didn’t bring the ball as high as with the old intake. . . We also made the intake much more secure with more supports and a stronger design. .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-03-26/roller-changes/",
    "relUrl": "/2021-03-26/roller-changes/"
  }
  ,"12": {
    "title": "Intake Log 2",
    "content": ". Preface | Objective | Problem | Plan | New Controls | Implementation Driver control | State overview | | Summary | Update March 28 | Preface . Upon analysis of the most optimal driver skills run, we realized the biggest factor that was impeding our time: we were pooping too early. We had always driven so that the robot would try to get rid of blue balls right away, which would keep the intakes empty. However, the blue balls that were pooped was causing pandemonium in the field, and knocking balls out of the way. . We realized that the best driving runs were repeatable and clean - dealing with a randomly jumbled field was not a good strategy. . If the robot held the blue balls and waited for a better time to poop, the blue balls would not cause the field to be jumbled. . To do this, I need to redesign the driver control scheme. . Objective . To rework the intake code to allow for holding the balls during driver control, allow for complex partner control, and simplify the code. . Problem . Currently, the intake code is structured in way so that each combination of buttons are represented by a state. This means shoot (rollers on, intake off) is a different state than on (all on), even though they require the same logic for autopooping, spaced shooting, ect. To add to the bloat, I needed non-pooping variants of each state to be able to control during autonomous. . This structure does not scale well, and will be difficult to change to support the new controls. . Plan . I have an idea to greatly simplify the statemachine. Currently, there is a unique enum (number) for each possible state. . For example, consider the states on, shoot, onWithoutPoop, and shootWithoutPoop. If we break down what each action represents: . State Intake Bottom Roller Top Roller Poop . on | yes | yes | yes | yes | . shoot | no | yes | yes | yes | . onWithoutPoop | yes | yes | yes | no | . shootWithoutPoop | no | yes | yes | no | . We notice there is a lot of duplication . The idea is, what if we can represent the robot in the binary representation of the state number? . For example, instead of on = 1, shoot = 2, etc, we have on = 0b1111, shoot = 0b0111, onWithoutPoop = 0b1110, ect. This will let us “build” states using bitwise logic, but still have each state named in an enum. There won’t need to be a LUT for the relation between state -&gt; should intake, for example. The code can directly measure whether something is enabled. . The best thing is, the state can both be treated as a distinct number, or a collection of flags! This makes it really versatile in programming. . In short: . Represent state as flag toggles | Use bit manipulation with bitmasks | Autopoop is off by default | Name all the states to be switchable in the inner statemachine | Assemble a state in driver control | Have a bitrange where actions not supported by the flag schema can be run (ex. a number for deploy) | . New Controls . To start off, let’s determine a new driver control scheme. Sawyer will be responsible for shooting, intaking of red balls, and driving. I will be responsible for dealing with the blue balls in the goals. I will have controls which I can use to intake the blue balls, stop the intake, and then enable auto auto poop. . Sawyer . L2: outtake all (poop) | R2: intake | R1: shoot | R1/R2: shoot and intake | L2/R2: intake while reversing rollers | L2/R1: outtake while shooting rollers | L2/R1/R1: on | . Theo . R2: intake (no poop) | R1: outtake (no poop) | R1/R2: stop and hold balls | . Outtake behaviour . outtake = outtake everything | outtake + intake = intake while reversing top = intake while sucking in failed shot, compacting (I think middle roller needs to be reversed) | outtake + shoot = shoot while outtaking intakes = follow through with shot while outtaking, get rid of balls as fast as possible (I think middle roller should be reversed) | outtake + shoot + intake = maybe just same as the last one except middle roller is normal direction | . Implementation . Driver control . First, we can refactor the driver control code to provide the new functionality and use the new api. . // initial state rollerStates state {rollerStates::off}; // if L2, add outtake if (master(L2)) { state |= rollerStates::out; } // if R2, add intake if (master(R2)) { state |= rollerStates::intake; } // partner controls if (partner(R2) &amp;&amp; partner(R1)) { state = rollerStates::off; } else if (partner(R2) || partner(B)) { state = rollerStates::intake; } else if (partner(R1)) { state = rollerStates::out; } else if (master(RIGHT)) { } else { // if none of the above buttons where pressed, then add poop state |= rollerStates::poop; } // partner can force poop if (partner(B)) { state |= rollerStates::poop; } // if R1, add shoot if (master(R1)) { state |= rollerStates::shoot; } // add actions if (either(B)) { state |= rollerStates::deploy; } else if (master(L1)) { state |= rollerStates::shootRev; } Robot::roller()-&gt;setNewState(state); . State overview . Then, we can design a binary scheme for the states and enum (name) them all: . // The first 3 bits toggle the state of each roller. // The next few bits modify the behavior of the rollers. // The last few bits enumerate additional actions. // Bits can be combined to represent compound states. enum class rollerStates { off = 0, // all off, no poop // toggle bits intake = 1 &lt;&lt; 0, // move intakes bottom = 1 &lt;&lt; 1, // move bottom roller top = 1 &lt;&lt; 2, // move top roller // modifier bits out = 1 &lt;&lt; 3, // reverse anything that is not enabled poop = 1 &lt;&lt; 4, // enable auto poop // action bits deploy = 1 &lt;&lt; 5, timedPoop = 2 &lt;&lt; 5, // poop for time backPoop = 3 &lt;&lt; 5, // bring blue down then poop shootRev = 4 &lt;&lt; 5, // bring rollers back manually // state combinations loading = intake | bottom, // load balls into robot. Disable rollers one by one. shoot = bottom | top, // all on but don&#39;t move intakes on = intake | bottom | top, // all on compact = out | intake, // reverse top and botton rollers while intaking fill = out | shoot, // shoot top and bottom while outtaking purge = out | top, // shoot top while reversing rest loadingPoop = loading | poop, shootPoop = shoot | poop, onPoop = on | poop, outPoop = out | poop, toggles = 0b00000111, // bitmask for roller toggles modifiers = 0b00011000, // bitmask for roller modifiers flags = 0b00011111, // bitmask for flags actions = 0b11100000, // bitmask for actions }; . Finally, the internal statemachine implementation is similar to before, but without a lot of redundant code: . Roller::colors Roller::getTopLight() const { if (topLight-&gt;getProximity() &lt; 100) return colors::none; int hue = topLight-&gt;getHue(); switch (hue) { case 160 ... 300: return colors::blue; case 0 ... 40: case 350 ... 360: return colors::red; default: return colors::none; } } Roller::colors Roller::getBottomLight() const { if (bottomLight-&gt;getProximity() &lt; 110) return colors::none; int hue = bottomLight-&gt;getHue(); switch (hue) { case 180 ... 300: return colors::blue; case 0 ... 40: case 350 ... 360: return colors::red; default: return colors::none; } } void Roller::runAction(const rs&amp; action) { // mark action start time macroTime.placeMark(); // clear prev action state &amp;= ~rs::actions; // add new action state |= action; } bool Roller::shouldPoop() { // if poop is not enabled, don&#39;t do anything if (!(state &amp; rs::poop)) return false; // if a blue is in the top, lower it before pooping if (getTopLight() == colors::blue) { runAction(rs::backPoop); return true; } // if blue ball in bottom but no red in top, poop it if (getBottomLight() == colors::blue &amp;&amp; getTopLight() != colors::red) { runAction(rs::timedPoop); return true; } return false; } int Roller::getIntake() { return !!(state &amp; rs::intake) ? 12000 : (!!(state &amp; rs::out) ? -12000 : 0); } void Roller::loop() { Rate rate; while (true) { // strip flags from action. If action, execute it, and skip flags. if (auto action = state &amp; rs::actions; action != rs::off) { switch (action) { case rs::deploy: top(12000); bottom(-800); intake(-12000); break; case rs::timedPoop: top(-12000); bottom(12000); intake(getIntake()); if (macroTime.getDtFromMark() &gt;= 200_ms) { runAction(rs::off); continue; } break; case rs::backPoop: top(-12000); bottom(-12000); intake(getIntake()); if (macroTime.getDtFromMark() &gt;= 100_ms) { runAction(rs::off); continue; } break; case rs::shootRev: top(-12000); bottom(-12000); intake(getIntake()); break; default: std::cout &lt;&lt; &quot;Error: action not found&quot; &lt;&lt; std::endl; break; } continue; } // run auto poop if needed if (shouldPoop()) continue; // if out is enabled bool out = !!(state &amp; rs::out); // strip toggles from state switch (auto toggles = state &amp; rs::toggles; toggles) { case rs::off: top(out ? -12000 : 0); bottom(out ? -12000 : 0); intake(out ? -12000 : 0); break; case rs::top: top(12000); bottom(out ? -12000 : 0); intake(out ? -12000 : 0); break; case rs::intake: if (out) { top(-12000); bottom(-12000); } else if (getTopLight() != colors::none &amp;&amp; getBottomLight() != colors::none) { top(0); bottom(0); } else if (getTopLight() != colors::none) { // balance between raising ball to prevent rubbing and bringing ball too high top(0); bottom(6000); } else { // balance between bringing ball too fast and accidentally pooping top(7000); // if there is a blue but it can&#39;t poop bottom(12000); } intake(12000); break; case rs::shoot: case rs::on: // don&#39;t shoot a blue ball if (getTopLight() == colors::blue) { // move to intake mode state &amp;= ~rs::shoot; top(-6000); pros::delay(100); continue; } else { top(12000); } // if red on the top needs to be separated from bottom ball if (getTopLight() == colors::red &amp;&amp; getBottomLight() != colors::none) { if (getBottomLight() == colors::blue) { bottom(0); } else { bottom(2000); } } else { bottom(12000); } intake(getIntake()); break; default: std::cout &lt;&lt; &quot;Error: toggle not found&quot; &lt;&lt; std::endl; break; } rate.delayUntil(5_ms); } } . Summary . In short, I took my statemachine to the next level by having the state enum represent its state in its binary form. . With the binary scheme defined in the rollerStates, “shoot with autopoop” is 0b00010110 and turning on the intakes would be flipping the first bit. . It’s really cool because you can treat it like a normal enum/statemachine, each state has a number, but you can also manipulate it as bitwise flags . So I can know which states have intake enabled, without needing a LUT or hardcoding it, and the driver code is super small. The driver code uses the bitwise representation of the state. . But the internal statemachine interprets the state as distinct states and switches between the possibilities, allowing for more complex logic. . Update March 28 . I finished tuning up the code and tested it on the robot for the first time. It worked perfectly first try! I’m looking forward to driver practice with the new controls and automation. .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-03-24/intake-log-2/",
    "relUrl": "/2021-03-24/intake-log-2/"
  }
  ,"13": {
    "title": "Robot V3",
    "content": "We will be taking V3 to Worlds. We have a bit of time for some larger-scale rebuilding, and then spend time perfecting our autonomous and driving. .",
    "url": "https://theol0403.github.io/7842B-Journal/build/v3/",
    "relUrl": "/build/v3/"
  }
  ,"14": {
    "title": "V2 Skills",
    "content": ". The new routine | Update March 3 | Update March 7 | For the competition of March 6, we plan to score all the goals. This would grant us a massive score thanks to completing all the combos. . However, some improvements need to be made from the last autonomous: . the starting orientation was not ideal, and it often caused the robot to knock the nearby ball into the way | at this point, the motion algorithms now support strafing and arcing, making many more routes possible | vision sensor alignment has been implemented, and seems to be very effective at improving consistency | planning locations where the robot poops is very important to ensure the field is in a consistent state | improving the intake timing is key to a consistent autonomous | . The new routine . Keeping all the above points in mind, here is the new routine, where red is forward, blue is backward, green is turning, and purple is strafing: . . In total, there are 13 point turns. Notice the use of the new algorithm for smooth arcing to the goal. . This autonomous builds upon v1, but introduces some more ambitious motions: the 3 curved arcs. However, we have a week to perfect it, so it should be doable. . Update March 3 . The new routine is coming along well, and with vision sensor allignment, it is about 90% consistent at grabbing the red balls and driving to the goals. . However, our largest source of error is from the timing of the intakes. Sometimes it leaves a blue ball in the goal. Sometimes it takes the red ball back out. . Iterating the entire autonomous just to tweak the intake timing was much too slow of a process, so instead, we developed a plan: . isolate the portion of the code responsible for a specific goal | set the robot up at that goal and run the code | tune the intake timing to be perfect | repeat for each goal | . This worked very well: after tuning all the intake code, our success rate went from about 40% to 80%. . Here is a video of the complete run: . . Update March 7 . At our provincials, the autonomous was executed perfectly, with a score of 121… except the worst of luck struck! At one of the goals, a blue ball was resting on the outer ledge, like so: . . Even though we had descored the ball, since it was inside the perimeter of the goal, it counted as scored. However, not only that, since it was slightly higher than the red ball (since it was on the lip), it counted the goal as blue-possessed. This fluke lost us 19 points! . Unfortunately, our other runs weren’t perfect, so while we made a few more points, we were unable to reach our maximum score. It was still enough for us to win the competition, however. . We learned that we need to be careful about outtaking the balls so that they don’t jam into the goals again. We also learned about the importance of tuning each goal individually for consistent results. .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-03-01/v2-skills/",
    "relUrl": "/2021-03-01/v2-skills/"
  }
  ,"15": {
    "title": "Upgrades",
    "content": "Intakes . For the new robot we decided to speed the intakes and shooting up. We made the top roller that shot the ball faster and lowered the amount of compression on the ball. This made it shoot better and not take as much pressure to shoot. We changed it to 1200Rpm. We also increased the rest of the intake and other roller speed to 600Rpm. This made the time to intake and score a lot faster. . Base . We also changed the wheels from 2.75 inch to 3.25 so that we could have higher speed to be able to do a full skills run. . . Intake sensors . Even though the light sensors were very effective at managing the intakes, we needed more information to remove driver work. We replaced both the light sensors with color sensors, which allows us to see the colors of the balls. This can let us add features like “auto poop”, “double shot”, “cycle and hold”, where the robot needs to know which balls are at what roller. . .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-02-28/upgrades/",
    "relUrl": "/2021-02-28/upgrades/"
  }
  ,"16": {
    "title": "Hood Changes",
    "content": "New Hood . The original hood that put compression on the ball to shoot but was not very secure, so we changed the hood to a more solid position. The hood is attached with a hinge and has a solid stop place which in theory should help shoot better. . . Hood Problems . When we remade it we made it have less compression on the ball since the made the shooting roller have more speed and less strength. We had some issues getting the right compression to be able to shoot fast enough but not to much that it would get jammed. We tried a few different thing to try to solve it like bending down the hood to increase compression and lowering the amount of elastics on the roller but it wasn’t working. . Then we had the idea of taking a slow-mo video of the robot shooting. We saw in the video the ball was spinning for a short amount of time at th bottom of the hood so it was not getting launched as far as it should so we moved the hole hood forward and bent back the hood so it had more compression at the bottom an the same at the top. .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-02-26/hood-changes/",
    "relUrl": "/2021-02-26/hood-changes/"
  }
  ,"17": {
    "title": "Deflector",
    "content": "For the new robot we decided to add a deflector that directs the ball into the goal. This majorly helps doing double shots and accuracy of the robot. . .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-02-23/deflector/",
    "relUrl": "/2021-02-23/deflector/"
  }
  ,"18": {
    "title": "Intake Log 1",
    "content": "I need to design a controller for the intakes. . Features: . use sensors to automatically shut off rollers when they hold a ball during intaking | automatically poop unwanted balls | space out balls when double shooting | execute actions like shoot, outtake, purge, etc | . To do this, I always start by defining all possible subsystem states: . enum class rollerStates { off, // all off offWithoutPoop, // all off out, // all backwards on, // all on onWithoutPoop, // all on without poop shoot, // all on but don&#39;t move intakes shootWithoutPoop, // all on but don&#39;t move intakes and don&#39;t poop intake, // load balls into robot. Disable rollers one by one, and auto poop intakeWithoutPoop, // load balls into robot. Disable rollers one by one poopIn, // poop while intaking poopOut, // poop while outtaking purge, // shoot while outtaking topOut, // only spin top roller deploy, timedPoop, timedShootPoop, spacedShoot, // all on but space the ball and no intakes topPoop, // bring down then poop }; . I can then plug in that state into my handy state machine helper: . class Roller : public StateMachine&lt;rollerStates, rollerStates::off&gt; { public: Roller(const std::shared_ptr&lt;AbstractMotor&gt;&amp; iintakes, const std::shared_ptr&lt;AbstractMotor&gt;&amp; ibottomRoller, const std::shared_ptr&lt;AbstractMotor&gt;&amp; itopRoller, const std::shared_ptr&lt;OpticalSensor&gt;&amp; itoplight, const std::shared_ptr&lt;OpticalSensor&gt;&amp; ibottomLight, const std::shared_ptr&lt;GUI::Graph&gt;&amp; igraph); public: enum class colors { none = 0, red, blue }; colors getTopLight() const; colors getBottomLight() const; bool shouldPoop(); bool shouldShootPoop(); bool shouldSpacedShoot(); int getIntake(); void initialize() override; void loop() override; std::shared_ptr&lt;AbstractMotor&gt; intakes {nullptr}; std::shared_ptr&lt;AbstractMotor&gt; bottomRoller {nullptr}; std::shared_ptr&lt;AbstractMotor&gt; topRoller {nullptr}; std::shared_ptr&lt;OpticalSensor&gt; topLight {nullptr}; std::shared_ptr&lt;OpticalSensor&gt; bottomLight {nullptr}; std::shared_ptr&lt;GUI::Graph&gt; graph {nullptr}; Timer macroTime; rollerStates macroReturnState = rollerStates::off; int macroIntakeVel = 12000; }; . Then, it is easy for me to design a driver control program: . if ((mDigital(L1) || mDigital(R2)) &amp;&amp; mDigital(R1)) { system(roller, on); } else if (mDigital(R1) &amp;&amp; mDigital(A)) { system(roller, on); } else if (mDigital(A)) { system(roller, poopIn); } else if (mDigital(R1)) { system(roller, shoot); } else if (mDigital(L2)) { system(roller, out); } else if (mDigital(B)) { system(roller, deploy); } else if (mDigital(LEFT)) { system(roller, poopOut); } else if (mDigital(DOWN)) { system(roller, topOut); } else if (mDigital(L1) || mDigital(R2)) { system(roller, intake); } else { system(roller, off); } . Finally, I can implement the statemachine states. . void Roller::loop() { Rate rate; while (true) { switch (state) { case rollerStates::off: if (shouldPoop()) continue; case rollerStates::offWithoutPoop: topRoller-&gt;moveVoltage(0); bottomRoller-&gt;moveVoltage(0); intakes-&gt;moveVoltage(0); break; case rollerStates::out: // if (shouldPoop(-12000)) continue; topRoller-&gt;moveVoltage(-12000); bottomRoller-&gt;moveVoltage(-12000); intakes-&gt;moveVoltage(-12000); break; case rollerStates::on: case rollerStates::shoot: if (shouldPoop()) continue; if (shouldShootPoop()) continue; [[fallthrough]]; case rollerStates::onWithoutPoop: case rollerStates::shootWithoutPoop: if (shouldSpacedShoot()) continue; topRoller-&gt;moveVoltage(12000); if (getBottomLight() == colors::blue) { if (getTopLight() != colors::red) { bottomRoller-&gt;moveVoltage(-2000); } else { bottomRoller-&gt;moveVoltage(2000); } } else { bottomRoller-&gt;moveVoltage(12000); } intakes-&gt;moveVoltage(getIntake()); break; case rollerStates::intake: if (shouldPoop()) continue; [[fallthrough]]; case rollerStates::intakeWithoutPoop: if (getTopLight() != colors::none &amp;&amp; getBottomLight() != colors::none) { topRoller-&gt;moveVoltage(0); if (getBottomLight() == colors::blue) { bottomRoller-&gt;moveVoltage(-2000); } else { bottomRoller-&gt;moveVoltage(0); } intakes-&gt;moveVoltage(12000); } else if (getTopLight() != colors::none) { // balance between raising ball to prevent rubbing and bringing ball too high topRoller-&gt;moveVoltage(1800); // slow down bottomRoller-&gt;moveVoltage(4000); intakes-&gt;moveVoltage(12000); } else { // balance between bringing ball too fast and accidentally pooping topRoller-&gt;moveVoltage(4000); if (getBottomLight() == colors::blue) { bottomRoller-&gt;moveVoltage(-2000); } else { bottomRoller-&gt;moveVoltage(12000); } intakes-&gt;moveVoltage(12000); } break; case rollerStates::poopIn: topRoller-&gt;moveVoltage(-12000); bottomRoller-&gt;moveVoltage(12000); intakes-&gt;moveVoltage(12000); break; case rollerStates::poopOut: topRoller-&gt;moveVoltage(-12000); bottomRoller-&gt;moveVoltage(12000); intakes-&gt;moveVoltage(-12000); break; case rollerStates::purge: topRoller-&gt;moveVoltage(12000); bottomRoller-&gt;moveVoltage(12000); intakes-&gt;moveVoltage(-12000); break; case rollerStates::topOut: topRoller-&gt;moveVoltage(12000); bottomRoller-&gt;moveVoltage(4000); intakes-&gt;moveVoltage(0); break; case rollerStates::deploy: topRoller-&gt;moveVoltage(12000); bottomRoller-&gt;moveVoltage(-800); intakes-&gt;moveVoltage(-12000); break; case rollerStates::timedPoop: topRoller-&gt;moveVoltage(-12000); bottomRoller-&gt;moveVoltage(12000); intakes-&gt;moveVoltage(macroIntakeVel); if (macroTime.getDtFromMark() &gt;= 200_ms) { macroTime.clearMark(); state = macroReturnState; continue; } break; case rollerStates::timedShootPoop: topRoller-&gt;moveVoltage(12000); bottomRoller-&gt;moveVoltage(0); intakes-&gt;moveVoltage(macroIntakeVel); if (macroTime.getDtFromMark() &gt;= 400_ms) { macroTime.placeMark(); state = rollerStates::timedPoop; continue; } break; case rollerStates::spacedShoot: topRoller-&gt;moveVoltage(12000); bottomRoller-&gt;moveVoltage(1000); intakes-&gt;moveVoltage(macroIntakeVel); if (macroTime.getDtFromMark() &gt;= 10_ms) { macroTime.clearMark(); state = macroReturnState; continue; } break; case rollerStates::topPoop: topRoller-&gt;moveVoltage(-12000); bottomRoller-&gt;moveVoltage(-12000); intakes-&gt;moveVoltage(macroIntakeVel); if (macroTime.getDtFromMark() &gt;= 150_ms) { macroTime.placeMark(); state = rollerStates::timedPoop; continue; } break; } rate.delayUntil(5_ms); } } . This code is versatile because it is . asynchronous | responsive | stateful (and the state can be easily retrieved and changed) | common between driving and autonomous | . It can: . intake and hold balls | shoot balls with spacing | automatically engage poop states which auto return to the original state | execute all the other actions needed | . However, this code is slightly messy and inflexible, but I have an idea to improve it in the next build log. .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-02-20/intake-log-1/",
    "relUrl": "/2021-02-20/intake-log-1/"
  }
  ,"19": {
    "title": "Robot V2",
    "content": "After attending two competitions with V1, we decided to make some major changes to improve the robot. . . We will take V2 to the next two competitions, which will be the last two until Worlds. .",
    "url": "https://theol0403.github.io/7842B-Journal/build/v2/",
    "relUrl": "/build/v2/"
  }
  ,"20": {
    "title": "V1 Skills",
    "content": "We have about 2 days to write a programming skills run. We are starting from scratch, apart from a skeleton of a 3-ball routine. However, the algorithms have changed and distances will not be the same as before. . Currently, we can only move in straight lines. It is using the 2D motion profile codebase, but there is an issue with following a spline. Therefore, we will only feed it lines, effectively turning it into a 1D motion profile. . The current rough plan: . . Where red is forward, blue is backward, green is turning, and orange is direction. . Hopefully, we will be able to pull this off for the Feb 6 competition. . Update Feb 6 . The routine exeeded our expectations, by actually scoring decently well! We managed to program all the steps in our plan. It missed a few goals at the competition, but by shooting for a higher number of goals than before, we won the competition and beat a personal best! . Here is a successful practice run: . . At this competition, we learned a lot, like the importance of planning where to poop, the need for some extra sensors for consistency, and generally what needs to be done to improve the autonomous. .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-02-04/v1-skills/",
    "relUrl": "/2021-02-04/v1-skills/"
  }
  ,"21": {
    "title": "Intake Design",
    "content": ". Front Intakes | Back Rollers | Intake sensors | Front Intakes . The robot was built so that the intakes could fold out to extend the reach of the robot into the goals. This was done by using nilocks and strand-offs. . Elastics are used to pull the intakes to the front and into position. The intakes rotate in until they hit the stopper. The stopper is made to be easily changed for the right amount of compression on the ball. The intakes run at 200 rpm. . . Back Rollers . The robot has rollers at the back that are spaced apart so that we can get rid of the balls out the back: . . The robot uses 2 motors for the rollers that move up and shoot the balls. Since there are 4 rollers each motor controls 2 rollers. . You can see the 4 rollers in his image: . . However, since our robot gets rid of the wrong-colored balls out the back which means they need to be able to spin opposite directions – either spit out the ball or send it up to score with. Therefore, the back rollers must be on different motors. . So, each one of the back rollers are connected to one of the front rollers but the front and back need to go opposite directions to move the ball up. To run two rollers opposite directions with one motor we made a gearbox to reverse the rotation. . The rollers that move the ball up or out the back run at 200 rpm and the one that shoots them runs at 600 rpm. . Lower reversing gearbox: . . Upper reversing gearbox: . . For shooting we made a 600 rpm roller with a hood made out of lexan and strapping for compression: . . Intake sensors . We knew that we wanted the driver to be able to hold the “intake” button without being worried that the robot will expel balls. Therefore, we attached light sensors to the intake and hood which can detect the presence of a ball. This way, we can automatically turn off the rollers when they are holding a ball. .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-01-20/intakes/",
    "relUrl": "/2021-01-20/intakes/"
  }
  ,"22": {
    "title": "Robot Chassis",
    "content": "X-Drive . We decided to make an X-drive chassis with 2.75” wheels and direct-drive 200 rpm motors. We chose an X-drive because of its good manoeuvrability and consistency. . Because the drive is holonomic, it can drive and strafe in all directions. The low speed and high torque makes it very controllable during autonomous. . .",
    "url": "https://theol0403.github.io/7842B-Journal/2021-01-15/chassis/",
    "relUrl": "/2021-01-15/chassis/"
  }
  ,"23": {
    "title": "Robot V1",
    "content": "This is our first robot. We built it in preparation for our first competition, and the plan was to get a feel for the game and virtual competition. . . It ended up performing quite well and winning us the competition! .",
    "url": "https://theol0403.github.io/7842B-Journal/build/v1/",
    "relUrl": "/build/v1/"
  }
  ,"24": {
    "title": "Trajectory Journal",
    "content": "To organize all my thoughts for this very complex project, I have created a project journal on the note-taking app Notion. It contains a linked tree of information about the project and ideas. . Notion Trajectory Generator Journal 🔗 . It is embedded here, but I recommend using the button above to go to the full screen page. .",
    "url": "https://theol0403.github.io/7842B-Journal/2020-06-22/trajectory-journal/",
    "relUrl": "/2020-06-22/trajectory-journal/"
  }
  ,"25": {
    "title": "Introduction",
    "content": ". Reflection Odometry | Closed-loop issues | | Requirements | Solutions Pure Pursuit | Open Loop Control | | Objectives | Existing Work | Basic Explanation 1D Motion | 2D Motion | Major Challenge | | Reflection . To execute any autonomous routine, the robot needs movement algorithms. These are functions that use sensors, controllers, and kinematics to move the robot somewhere. . My focus in VEX has been developing such algorithms: . 2018: Tank drive odometry PID (taken from here) | 2019: X drive odometry PID | 2019: Pure Pursuit | . All these algorithms can achieve various motions and require odometry. However, they all have various weaknesses. . Odometry . The main use of odometry is to unlock many possibilities of motion control. This is because you now have access to much more information that you can feed into the algorithms. For example, if you know the coordinates of the robot, and you want to drive to some other coordinate, it is trivial to calculate position and orientation error and then use PID-based algorithms to minimize that error. . Odometry, however, is a tricky task: . it drifts a ton | it requires a robot designed with perfectly calibrated tracking wheels | it requires much tuning | it is sensitive to rocking, vibrations, etc | . Closed-loop issues . Assuming the robot has perfectly tuned odometry, you still run into issues. This is because anything directly using odometry is inherently a closed loop controller. This means that the controller’s output is a direct function of the robot’s error (calculated from state). . . While this theoretically seems like a good thing, as the robot can use sensors to correct for disturbances and errors, consider some realities: . in VEX (especially skills), there is nothing that will interfere with the robot | if something is wrong, misalligned, or stuck, odometry can’t fix that | using vex sensors for localization is not accurate, fast, or smooth | . Instead, what ends up happening is that odom introduces noise and variance into the controller, in a vicious cycle of tracking error -&gt; correction -&gt; more error -&gt; unpredictable error. . Is the definition of smooth, consistent control “do the exact same thing every time”, or “aggressively minimize error until the sensors say you are at your destination”? I believe it is the former. . Requirements . Is there a way to achieve the benefits of odometry (more complex and versatile algorithms) without being overreliant on sensors? . I need to develop a motion algorithm that matches the following criteria: . follow any arbitrary path that is represented by a mathematical function | use robot kinematics and math to ensure smooth, consistent control by default | remove a dependence on difficult and noisy sensors | support sensor augmentation which can use sensors to correct, not steer | . This season, driving complex paths will be very useful. Therefore, while moving in straight lines/arcs is useful, we need more. . Specifically, we want the robot to follow a parametric spline. A parametric spline is a function that gives ((x, y) ) as a function of (t ). . . We need to design an algorithm that takes a spline as an input and outputs motor voltages for each side of the robot. . Solutions . Pure Pursuit . One option is Pure Pursuit, an algorithm that uses odometry to project a point along a spline for it to “seek”. . However, since pure pursuit is a closed-loop controller that takes the robot’s current state, measured by sensors (position, speed), and calculates how the robot should move, it falls into the problems with closed-loop control mentioned above - namely this it is unstable, unpredictable, inconsistent, and not smooth. . . Open Loop Control . What if we made an algorithm that generates wheel velocities for the robot to follow exactly: . An open loop controller plans how it will move ahead of time. | The motion is guaranteed to be smooth, consistent, optimal, and therefore repeatable | Any tracking error will often be repeatable | . However, this means we need to be more deliberate with the calculations. Any errors won’t be compensated for. If the smooth control is not consistent enough, sensors can be used to correct the motion. . . In short, we want to design a trajectory generator, where the input is a spline, and the output is wheel velocites. . Objectives . First, let’s define some objectives for our generator: . We want to develop a trajectory generator that will take a spline as an input and output a list of wheel speeds | We want to respect the robot’s kinematics (top motor speed and acceleration) | We want the output to be as smooth and accurate as possible | We want the generator to be fast enough that we can regenerate while following | . . Existing Work . Similar projects have been created: . WPILib | Pathfinder Pathfinder 1 | Pathfinder 2 | . | Sqiggles | . However, this project attempts to beat them all, both in theoretical accuracy and generation speed. . Basic Explanation . A trajectory generator is made by combining many steps together to form a final product. . 1D Motion . Let’s say we want the robot to drive a specific distance in a straight line. How can we do this without sensors? How can we make the motion smooth and accurate? . . The solution is called a motion profile. A motion profile plans the velocity of the robot over time while respecting kinematics (top motor speed and acceleration). . Specifically, whe want to use a trapezoidal motion profile. In such a profile, the robot accelerates, cruises at full speed, then decelerates. We can solve this profile in such a way that the robot travels a specific distance (area under the graph). . . 2D Motion . How can we apply a motion profile to a spline? If we analyze how we want the robot to drive: . Start: we want to start at 0 velocity and accelerate | Middle: we want to be moving at the maximum speed possible | End: we want to decelerate to 0 velocity | . What if we map the distance along the spline to the distance of the motion profile? . First we need the motion profile to be a function of distance, not time. That way, we can look at our progress along the spline, and we can find out what velocity we should be travelling at! . . Finally, we have all the tools we need to start the main algorithm: . Measure the length of the spline, and solve a motion profile for that distance | Start at the beginning of the spline | What velocity should I be moving given the distance travelled? | What is the curvature of the spline? | Given the formula (angular _velocity = linear _velocity cdot curvature ) , what is my angular velocity? | Record the linear and angular velocity at (time=0 ) | Wait (0.01s ), then (delta _distance = linear _velocity * 0.01 ) | Move (delta _distance ) along the spline | Repeat at new distance | . If we can implement all these steps, we can achieve the fundamental structure of the trajectory generator! . Major Challenge . The hardest part about this project is the following: . Given a spline, what is its arc length? | Given a spline, what new value of (t ) do I use after I’ve traveled a certain distance? | . Recall that a spline is ((x, y) ) as a function of (t ), in the range ([0, 1] ). . The only way to find arc length of any subset of a spline is extremely inefficient. It involves moving (t ) in very small increments, and measuring the distances between each point along the spline. After summing the distances, we have the arc length. This takes seconds of time. .",
    "url": "https://theol0403.github.io/7842B-Journal/2020-06-01/introduction/",
    "relUrl": "/2020-06-01/introduction/"
  }
  ,"26": {
    "title": "lib7842",
    "content": "What is lib7842? . lib7842 is a PROS library for advanced controls which is built around OkapiLib. It is designed to be a good example for advanced programming and a useful tool for competition. . I have been working of lib7842 since summer 2019, and plan on releasing it to the VEX community by summer 2020. I will use it for competition through the season, which will not only provide testing and experience, but also provide a direction and motivation for the library. . I have shared the library with some teams in the US who are part of TVA for testing and collaboration purposes. . What will lib7842 provide? . The core of lib7842 will be: . Fluent path generation API | Pure Pursuit path follower | Pure Pursuit X-Drive path follower | Odometry-based PID motion controller | Odometry-based PID X-Drive controller | Flexible GUI library | Vision sensor management and filtering | . There are other utilities and functionality in lib7842, but these are the main elements of it. . Programming Practices: . lib7842 is a full library that will be used by many VEX competitors. To deliver the best product possible, I am learning how to follow the best C++ coding standards and practices for lib7842. . Git Make a commit for every change made | Use imperative tense for commit messages | Use git flow for source and feature management | . | Formatting Format all code using clang-format | . | CI and Tests Tests need to be made for each public API | Each commit is compiled and tested by Azure Pipelines | CI Results V5 binary and template | Test results | Valgrind memory leak detector results | Callgrind profiler results | CppCheck static analysis | Codacity static analysis | Codefactor static analysis | . | . | . Commit Messages . Here is an example of lib7842 commit messages, which are intended to be as informative as possible: . .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-11-28/lib7842/",
    "relUrl": "/2019-11-28/lib7842/"
  }
  ,"27": {
    "title": "Pure Pursuit",
    "content": "Pure pursuit is a path following algorithm. Using odometry information and a path, pure pursuit controls how the robot should move to follow the path. . Pure pursuit has a few advantages: . Motion profile capabilities: acceleration and velocity constraints | Expressive arcs and curves | Dynamic and feedback-based correction | . A great paper on adaptive pure pursuit can be found here. . How it works . Pure pursuit works by finding a lookahead on the path. It does this by finding the intersection of a circle of a given radius with the path. Then, the robot seeks the lookahead by calculating curvature and velocity to reach the lookahead. . . . Implementing Pure Pursuit . To test pursuit, I wrote a full simulation using javascript. I was able to implement all the logic and optimization in that controlled environment. Implementing algorithms in javascript is very useful, as it provides a visual way of testing the algorithm and the code can translate to C++ quite easily. This algorithm has been in progress since June 2019. . Here are the controls: . Ctrl + Right-click to place robot | Click to place node | Click and drag to move node | Right-click node to delete | Right-click and drag to delete selection | . Here are the sliders: . Sample resolution: how many points should be generated from the path formula | Smoothing constant: how smooth should the connections between segments be | Lookahead distance: how far along the path should the robot look | Code . The majority of the code currently in lib7842 is used for pure pursuit. This includes path representations, path creation and interpolation, path velocity generation (motion profile), as well as the actual path follower. . Here is an example code for pure pursuit: . auto path = SimplePath({odom-&gt;getState(), {0_ft, 0_ft}, {0_ft, 4_ft}}) .generate(1_mm) .smoothen(.001, 1e-10 * meter); follower.followPath(PathGenerator::generate(path, limits), false); . Update March 16 . I worked on pure pursuit a bunch more during lockdown, and implemented a holonomic version. It worked quite well, but was somewhat unstable. . Skid-steer . Holonomic .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-11-25/pure-pursuit/",
    "relUrl": "/2019-11-25/pure-pursuit/"
  }
  ,"28": {
    "title": "Odom X Controller",
    "content": ". Directional Drive | PID Seeking | Turning While Driving | OdomXController Code | Having an X-Drive allows for much more complex algorithms. Not only can it move in all directions, but it can move independently of heading. This allows the robot to drive while turning, which is very useful for competition. . As of writing this, none of my autonomous programs use any turn commands, because all the required turning is handled while driving. . Directional Drive . I have made a function that allows me to tell the robot to drive in a certain direction. Using this math I can tell the chassis to strafe at a certain direction and speed. . . Here is the lib7842 implementation of this functionality: . /** * Control the chassis movement for an XDrive using voltage. Strafes at the given voltage in the * given direction. Applies magnitude control to prioritize turning. Range of forward, yaw, and * strafe is +-1, but yaw may be outside of the range which prioritizes turning. * * @param model The chassis model * @param forward The forward voltage * @param yaw The yaw voltage * @param direction The direction */ void strafeVector(const std::shared_ptr&lt;XDriveModel&gt;&amp; model, double forward, double yaw, const QAngle&amp; direction); . PID Seeking . Driving to a point with an X-Drive is much easier than with a skid-steer drive. This is because the direction of the robot does not depend on the heading of the robot, which eliminates oscillation and other issues. . Driving to a point is as simple as using odometry to calculate the angle and distance to the target point. I then apply PID to the distance error to determine the speed at which the robot should be moving. . I can then use the above function to apply the PID output to the desired direction. Doing this, the robot will always move towards the target point, and it even handles settling really well. . Turning While Driving . Using the above calculations, turning while driving is quite easy to implement. I simply use an AngleCalculator to calculate the desired turning amount. I apply PID to the output of the AngleCalculator, and then combine that with the output of the movement command. . Using an AngleCalculator to calculate the desired angle is quite useful, as I can use it to tell the robot to face a point or angle while driving, as well as turn while driving. . Here is the lib7842 implementation of X-Drive movement: . void OdomXController::strafeToPoint(const Vector&amp; targetPoint, const AngleCalculator&amp; angleCalculator, double turnScale, const Settler&amp; settler) { resetPid(); auto rate = timeUtil.getRate(); do { State state = getState(); distanceErr = state.distTo(targetPoint); angleErr = angleCalculator(*this); QAngle angleToTarget = angleToPoint(targetPoint); double distanceVel = distanceController-&gt;step(-distanceErr.convert(millimeter)); double angleVel = angleController-&gt;step(-angleErr.convert(degree)); strafeVector(xModel, distanceVel, angleVel * turnScale, angleToTarget); rate-&gt;delayUntil(10_ms); } while (!settler(*this)); driveVector(xModel, 0, 0); } . OdomXController Code . /** * Odometry motion controller for X-Base chassis. */ class OdomXController : public OdomController { public: /** * OdomXController. Implements chassis movement algorithms for the X drive. * * @param imodel The chassis model * @param iodometry The chassis odometry * @param idistanceController The distance pid controller * @param iturnController The turning pid controller * @param iangleController The angle pid controller, used to keep distance driving straight */ OdomXController(const std::shared_ptr&lt;XDriveModel&gt;&amp; imodel, const std::shared_ptr&lt;Odometry&gt;&amp; iodometry, std::unique_ptr&lt;IterativePosPIDController&gt; idistanceController, std::unique_ptr&lt;IterativePosPIDController&gt; iturnController, std::unique_ptr&lt;IterativePosPIDController&gt; iangleController, const TimeUtil&amp; itimeUtil); virtual ~OdomXController() = default; /** * Strafe a distance in a relative direction while correcting angle using an AngleCalculator * * @param distance The distance * @param direction The relative direction of the strafing * @param angleCalculator The angle calculator * @param turnScale The turn scale * @param settler The settler */ virtual void strafeRelativeDirection(const QLength&amp; distance, const QAngle&amp; direction, const AngleCalculator&amp; angleCalculator = makeAngleCalculator(), double turnScale = 1, const Settler&amp; settler = defaultDriveAngleSettler); /** * Strafe a distance in an absolute direction while correcting angle using an AngleCalculator * * @param distance The distance * @param direction The absolute direction of the strafing * @param angleCalculator The angle calculator * @param turnScale The turn scale * @param settler The settler */ virtual void strafeAbsoluteDirection(const QLength&amp; distance, const QAngle&amp; direction, const AngleCalculator&amp; angleCalculator = makeAngleCalculator(), double turnScale = 1, const Settler&amp; settler = defaultDriveAngleSettler); /** * Strafe to a point using field-centric math and an AngleCalculator * * @param targetPoint The target point * @param angleCalculator The angle calculator * @param turnScale The turn scale * @param settler The settler */ virtual void strafeToPoint(const Vector&amp; targetPoint, const AngleCalculator&amp; angleCalculator = makeAngleCalculator(), double turnScale = 1, const Settler&amp; settler = defaultDriveAngleSettler); protected: std::shared_ptr&lt;XDriveModel&gt; xModel {nullptr}; }; .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-11-20/odom-x-controller/",
    "relUrl": "/2019-11-20/odom-x-controller/"
  }
  ,"29": {
    "title": "Odom Controller",
    "content": ". Basic Movement PID to Heading and Distance | | Adaptive PID Seeking | Settling | Turning | OdomController Code | In order to move to specific coordinates, I needed to design a versatile controller to allow me to tell the robot to drive to a point, using odometry information. This is quite a complex task, as it involves moving the robot in two dimensions while being efficient. . Basic Movement . Once you know the position of the robot and where you want to move, the challenge is to actually move there. Here is a very simple algorithm to drive to a point: . Calculate angle to target | Turn to face the target | Calculate distance to target | Move distance to reach target | While this algorithm works decently well, it is quite slow and is not able to dynamically adjust while on-course. I instead wanted to make an algorithm that would curve toward the target, and calculate course adjustments on the fly. . PID to Heading and Distance . The first algorithm I tried was PID. The distance and angle to the target would be sent to 2 PID controllers, and then the outputs would be combined. There were two problems with this method. . The first was that the algorithm had to be terminated when the robot reached the general vicinity of the target, or else the robot would start having a spasm. This is because the PID needs to have a negative input signal to be able to back up and settle. . However, when calculating distance to a point (using Pythagoras), you can’t know when you overshoot the target. Therefore, the robot could only move forward, so when it reaches and overshoots the target, the angle to the target flips 180 degrees and the distance PID goes full throttle. . The second problem with this method is that it is not the most efficient. If the robot was perpendicular to the target, the distance PID would output full power, even though moving forward is the wrong thing to do. . . Instead, I wanted an algorithm that prioritized turning over moving, and that only moves when doing so would make the robot get nearer to the target. . Adaptive PID Seeking . I posed this question: “If the robot is locked to its current heading, so it can only move forward/backward, how can it move in a straight line to get closest to the point as possible?”. . If the robot was perpendicular to the target, the answer would be 0. But as the robot rotates to face the target, the answer becomes more and more. Here are some images illustrating the question (the answer is the length of the red line): . . After some research and help, I was able to implement the math for this. When doing distance PID on the output of these calculations, the robot was able to move much more efficiently. I also had to implement some logic to be able to drive backward. . The reason this algorithm works great for settling is that if I turn off the angle PID when the robot is a certain distance away from the target, the adaptive distance PID brings the robot to a settled stop, giving a negative signal to back up. . To test this algorithm, I made a javascript simulation. You can see how the robot prefers turning over driving, and how it settles smoothly: . ![](images/479e47a7761f01d48f5c41f49bfbaeaf4f75f1c8.gif) Settling . Every single autonomous motion has a settling period. However, I wanted the settling to be customizable for every single command. I wanted to be able to settle a few different ways: . All PID controllers come to a rest | All PID controllers get to some margin of error | The robot gets to a certain requirement, such as a certain distance from a point or a certain angle | . To do this, I created a parameter in each movement function that accepts a special kind of function called a Settler. Every loop, the movement function will ask the settler “am I settled yet?” and then the function will return true when it’s conditions are met. . Here is the lib7842 implementation of a Settler: . /** * Function that returns true to end chassis movement. Used to implement different settling methods. */ using Settler = std::function&lt;bool(const OdomController&amp; odom)&gt;; . Then, I created a few default settling functions and added the functionality to generate new settling functions on the fly. For example, here is a command with a settler that waits for all the PID controllers to settle. . driveToPoint({1_ft, 1_ft}, 1, driveSettle); . If I wanted to make the robot exit the movement when it was 4 inches away from the target, I could use a distance-based settler. . driveToPoint({1_ft, 1_ft}, 1, makeSettle(4_in)); . Here are some examples of settler creators: . /** * Make a Settler that exits when angle error is within given range * @param angle The angle error threshold */ static Settler makeSettler(const QAngle&amp; angle); /** * Make a Settler that exits when distance error is within given range * @param distance The distance error threshold */ static Settler makeSettler(const QLength&amp; distance); . Turning . All turning is essentially the same motion. The only difference with all possible turns is the goal calculation and movement method (point, pivot, or arc). I wanted to write only one turning algorithm, and have all the implementations plug-in. . Thus I used the same modular function pattern as the settling system and added parameters in the turning function to fulfill the angle calculation and movement method. Here are a few examples of a turn command: . turn(makeAngle({1_ft, 1_ft}), pointTurn, turnSettle); turn(makeAngle(90_deg), leftPivot, makeSettle(5_deg)); . Here is the lib7842 implementation of Turner and AngleCalculator: . /** * Function that accepts a turning velocity and controls execution to the chassis. Used to implement * a point or pivot turn. */ using Turner = std::function&lt;void(ChassisModel&amp; model, double vel)&gt;; /** * Function that returns an angle for the chassis to seek. Examples can be an AngleCalculator that * returns the angle to a point, or an angle to an absolute angle. */ using AngleCalculator = std::function&lt;QAngle(const OdomController&amp; odom)&gt;; . Here is the basis turn function that all other turns use: . /** * Turn the chassis using the given AngleCalculator * * @param angleCalculator The angle calculator * @param turner The turner * @param settler The settler */ virtual void turn(const AngleCalculator&amp; angleCalculator, const Turner&amp; turner = pointTurn, const Settler&amp; settler = defaultTurnSettler); . Here are a few AngleCalculator creators: . /** * Make an AngleCalculator that seeks a given absolute angle * * @param angle The angle */ static AngleCalculator makeAngleCalculator(const QAngle&amp; angle); /** * Make an AngleCaclulator that seeks a given point. * * @param point The point */ static AngleCalculator makeAngleCalculator(const Vector&amp; point); . These AngleCalculators will provide the foundation on which to build X-Drive control on. . I also made a few helper functions to provide more expressive turning commands: turnToAngle(angle), turnAngle(angle), and turnToPoint(point), which all just call turn(angleCalc) internally. . OdomController Code . Here is the entire OdomController header: . /** * Function that returns true to end chassis movement. Used to implement different settling methods. */ using Settler = std::function&lt;bool(const OdomController&amp; odom)&gt;; /** * Function that accepts a turning velocity and controls execution to the chassis. Used to implement * a point or pivot turn. */ using Turner = std::function&lt;void(ChassisModel&amp; model, double vel)&gt;; /** * Function that returns an angle for the chassis to seek. Examples can be an AngleCalculator that * returns the angle to a point, or an angle to an absolute angle. */ using AngleCalculator = std::function&lt;QAngle(const OdomController&amp; odom)&gt;; /** * Odometry motion controller for skid-steer chassis. */ class OdomController { public: /** * OdomController. Implements chassis movement algorithms * * @param imodel The chassis model * @param iodometry The chassis odometry * @param idistanceController The distance pid controller * @param iturnController The turning pid controller * @param iangleController The angle pid controller, used to keep distance driving straight * @param isettleRadius The radius from the target point to give up angle correction * @param itimeUtil The time utility */ OdomController(const std::shared_ptr&lt;ChassisModel&gt;&amp; imodel, const std::shared_ptr&lt;Odometry&gt;&amp; iodometry, std::unique_ptr&lt;IterativePosPIDController&gt; idistanceController, std::unique_ptr&lt;IterativePosPIDController&gt; iturnController, std::unique_ptr&lt;IterativePosPIDController&gt; iangleController, const QLength&amp; isettleRadius, const TimeUtil&amp; itimeUtil); virtual ~OdomController() = default; /** * Turn the chassis using the given AngleCalculator * * @param angleCalculator The angle calculator * @param turner The turner * @param settler The settler */ virtual void turn(const AngleCalculator&amp; angleCalculator, const Turner&amp; turner = pointTurn, const Settler&amp; settler = defaultTurnSettler); /** * Turn the chassis to face an absolute angle * * @param angle The angle * @param turner The turner * @param settler The settler */ virtual void turnToAngle(const QAngle&amp; angle, const Turner&amp; turner = pointTurn, const Settler&amp; settler = defaultTurnSettler); /** * Turn the chassis to face a relative angle * * @param angle The angle * @param turner The turner * @param settler The settler */ virtual void turnAngle(const QAngle&amp; angle, const Turner&amp; turner = pointTurn, const Settler&amp; settler = defaultTurnSettler); /** * Turn the chassis to face a point * * @param point The point * @param turner The turner * @param settler The settler */ virtual void turnToPoint(const Vector&amp; point, const Turner&amp; turner = pointTurn, const Settler&amp; settler = defaultTurnSettler); /** * Drive a distance while correcting angle using an AngleCalculator * * @param distance The distance * @param angleCalculator The angle calculator * @param turnScale The turn scale * @param settler The settler */ virtual void moveDistanceAtAngle(const QLength&amp; distance, const AngleCalculator&amp; angleCalculator, double turnScale, const Settler&amp; settler = defaultDriveAngleSettler); /** * Drive a distance while maintaining starting angle * * @param distance The distance * @param settler The settler */ virtual void moveDistance(const QLength&amp; distance, const Settler&amp; settler = defaultDriveAngleSettler); /** * Drive to a point using custom point seeking * * @param targetPoint The target point * @param turnScale The turn scale used to control the priority of turning over driving. A * higher value will make the robot turn to face the point sooner * @param settler The settler */ virtual void driveToPoint(const Vector&amp; targetPoint, double turnScale = 1, const Settler&amp; settler = defaultDriveAngleSettler); /** * Drive to a point using simple point seeking * * @param targetPoint The target point * @param turnScale The turn scale used to control the priority of turning over driving. A * higher value will make the robot turn to face the point sooner * @param settler The settler */ virtual void driveToPoint2(const Vector&amp; targetPoint, double turnScale = 1, const Settler&amp; settler = defaultDriveAngleSettler); /** * A Settler that is used for turning which uses the turning pid&#39;s isSettled() method */ static bool defaultTurnSettler(const OdomController&amp; odom); /** * A Settler that is used for driving which uses the distance pid&#39;s isSettled() method */ static bool defaultDriveSettler(const OdomController&amp; odom); /** * A Settler that is used for driving which uses the distance and angle pid&#39;s isSettled() method */ static bool defaultDriveAngleSettler(const OdomController&amp; odom); /** * A Turner that executes a point turn which turns in place. Used as default for turn functions */ static void pointTurn(ChassisModel&amp; model, double vel); /** * A Turner that executes a left pivot, meaning it only moves the left motors. */ static void leftPivot(ChassisModel&amp; model, double vel); /** * A Turner that executes a right pivot, meaning it only moves the right motors. */ static void rightPivot(ChassisModel&amp; model, double vel); /** * Make a Settler that exits when angle error is within given range * @param angle The angle error threshold */ static Settler makeSettler(const QAngle&amp; angle); /** * Make a Settler that exits when distance error is within given range * @param distance The distance error threshold */ static Settler makeSettler(const QLength&amp; distance); /** * Make a Settler that exits when both angle and distance error is within given range. * @param angle The angle error threshold * @param distance The distance error threshold */ static Settler makeSettler(const QLength&amp; distance, const QAngle&amp; angle); /** * Make an AngleCalculator that seeks a given absolute angle * * @param angle The angle */ static AngleCalculator makeAngleCalculator(const QAngle&amp; angle); /** * Make an AngleCaclulator that seeks a given point. * * @param point The point */ static AngleCalculator makeAngleCalculator(const Vector&amp; point); /** * Make an AngleCaclulator that returns a constant error. The default settler needs to be changed * for a command using this calculator to settle. * * @param error The error * @return The angle calculator. */ static AngleCalculator makeAngleCalculator(double error); /** * Make an AngleCalculator that does nothing */ static AngleCalculator makeAngleCalculator(); /** * Get the odometry state. */ State getState() const; /** * Calculate distance from the chassis to the point */ QLength distanceToPoint(const Vector&amp; point) const; /** * Calculate angle from the chassis to the point */ QAngle angleToPoint(const Vector&amp; point) const; protected: /** * Reset the pid controllers, used before every motion */ virtual void resetPid(); std::shared_ptr&lt;ChassisModel&gt; model {nullptr}; std::shared_ptr&lt;Odometry&gt; odometry {nullptr}; std::unique_ptr&lt;IterativePosPIDController&gt; distanceController {nullptr}; std::unique_ptr&lt;IterativePosPIDController&gt; angleController {nullptr}; std::unique_ptr&lt;IterativePosPIDController&gt; turnController {nullptr}; const QLength settleRadius; TimeUtil timeUtil; QAngle angleErr = 0_deg; QLength distanceErr = 0_in; }; . Here is the motion algorithm to drive to a point using the adaptive seeking method: . void OdomController::driveToPoint(const Vector&amp; targetPoint, double turnScale, const Settler&amp; settler) { resetPid(); auto rate = timeUtil.getRate(); do { State state = getState(); Vector closestPoint = closest(state, targetPoint); QAngle angleToClose = state.angleTo(closestPoint); QAngle angleToTarget = state.angleTo(targetPoint); QLength distanceToClose = state.distTo(closestPoint); QLength distanceToTarget = state.distTo(targetPoint); // go backwards if (angleToClose.abs() &gt;= 90_deg) distanceToClose = -distanceToClose; if (distanceToTarget.abs() &lt; settleRadius) { angleErr = 0_deg; // used for settling distanceErr = distanceToClose; } else { angleErr = angleToTarget; // used for settling distanceErr = distanceToTarget; } // rotate angle to be +- 90 angleErr = rotateAngle90(angleErr); double angleVel = angleController-&gt;step(-angleErr.convert(degree)); double distanceVel = distanceController-&gt;step(-distanceToClose.convert(millimeter)); driveVector(model, distanceVel, angleVel * turnScale); rate-&gt;delayUntil(10_ms); } while (!settler(*this)); driveVector(model, 0, 0); } .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-11-15/odom-controller/",
    "relUrl": "/2019-11-15/odom-controller/"
  }
  ,"30": {
    "title": "Unit Tests",
    "content": "lib7842 is a library that will be released to many teams around the world. In order to make it as bug-free and reliable as possible, all classes have tests written for them. These tests check to make sure all the code is working as expected, and that there are no crashes or bugs. . Tests are run by Azure Pipelines CI. Every commit I make on GitHub gets processed and tested in the cloud, with the results reported back to me. The automated process also runs static analysis via CppCheck, which can find bugs in my code. Finally I run valgrind and callgrind, a memory leak and profiler tool. . . Tests . I use a testing framework called doctest. It allows me to write expressive tests through the TDD (Test Driven Development) workflow. . Here is an example test: . GIVEN(&quot;a data point with some data&quot;) { DataPoint point1 {5_in, 3_in}; point1.setData(&quot;curvature&quot;, 5.0); point1.setData(&quot;distance&quot;, 5_m); point1.setData(&quot;velocity&quot;, 5_mps); point1.setData(&quot;segmentIndex&quot;, 5); THEN(&quot;constructors should work&quot;) { DataPath(); DataPath({point1}); DataPath({point1, point1}); DataPath(std::vector&lt;DataPoint&gt;({point1, point1})); } GIVEN(&quot;a path containing three points&quot;) { DataPath path({point1, point1, point1}); THEN(&quot;the size of the path should be three&quot;) { REQUIRE(path().size() == 3); } THEN(&quot;each point should contain data&quot;) { for (auto&amp;&amp; point : path()) { CHECK(point-&gt;getData&lt;double&gt;(&quot;curvature&quot;) == 5.0); CHECK(point-&gt;getData&lt;QLength&gt;(&quot;distance&quot;) == 5_m); CHECK(point-&gt;getData&lt;QSpeed&gt;(&quot;velocity&quot;) == 5_mps); CHECK(point-&gt;getData&lt;int&gt;(&quot;segmentIndex&quot;) == 5); } } GIVEN(&quot;a simple path generated from the data path&quot;) { SimplePath ipath = path.generate(); THEN(&quot;the size of the path should be three&quot;) { REQUIRE(ipath().size() == 3); } THEN(&quot;the positions should be the same&quot;) { for (auto&amp;&amp; point : ipath()) { CHECK(*point == point1); } } } } } . If any of the tests fail, I will be notified and I will be able to solve the problem. Tests have already found many bugs I would have missed, and is a great way to test code without needing a robot. . .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-11-10/tests/",
    "relUrl": "/2019-11-10/tests/"
  }
  ,"31": {
    "title": "GUI",
    "content": "A large part of lib7842 is the GUI. It uses a third-party graphics library named LVGL for the elements. The GUI is fully tested and developed on my computer using a simulator, so that I don’t need to have a V5 brain handy. . Here is a screenshot of the GUI: . .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-10-19/gui/",
    "relUrl": "/2019-10-19/gui/"
  }
  ,"32": {
    "title": "Task Wrapper",
    "content": "If a class requires a task as a member, it causes some problems. A pros::Task requires a callback function to run, but due to some limitations in c++, the address of that function needs to be known in compile-time. This means that the task callback needs to be static , which means that it does not belong to the class instance and it can’t access class members. To fix this, a pattern named trampoline is used. Trampoline is the act of passing a opaque pointer to the class object through the task to be received by the static function, having the static function cast the pointer to the correct class type, and calling a member function to execute the task. . Since implementing a trampoline requires a solid amount of boilerplate, I have written an abstract task wrapper that does this for me. To be able to run using unit tests and CI, I am using OkapiLib’s CrossPlatformTask as the task object. . Note how the this pointer is passed when task is constructed: . task = std::make_unique&lt;CrossplatformThread&gt;(trampoline, this, iname.c_str()); . Then, the pointer is cast by the trampoline and a virtual member loop() is called, which is then resolved by dynamic binding: . void TaskWrapper::trampoline(void* iparam) { pros::delay(20); static_cast&lt;TaskWrapper*&gt;(iparam)-&gt;loop(); } . Here is the full TaskWrapper implementation: . /** * A utility class that wraps a task trampoline. To use, simply inherit your class from TaskWrapper * and override the `loop` method. To start the task, the `startTask` method must be called, either * from the constructor or from outside the class. */ class TaskWrapper { protected: explicit TaskWrapper(const std::shared_ptr&lt;Logger&gt;&amp; ilogger = Logger::getDefaultLogger()); TaskWrapper(const TaskWrapper&amp; itask) = delete; TaskWrapper(TaskWrapper&amp;&amp; itask) = default; virtual ~TaskWrapper() = default; /** * Override this function to implement a custom task loop. * Will throw if not overridden. */ virtual void loop(); public: /** * Start the task. * * @param iname The task name, optional. */ virtual void startTask(const std::string&amp; iname = &quot;TaskWrapper&quot;); /** * Kill the task. */ virtual void killTask(); /** * Get the task name. * * @return The name. */ virtual std::string getName(); protected: std::shared_ptr&lt;Logger&gt; logger {nullptr}; private: static void trampoline(void* iparam); std::unique_ptr&lt;CrossplatformThread&gt; task {nullptr}; }; . Source file: . TaskWrapper::TaskWrapper(const std::shared_ptr&lt;Logger&gt;&amp; ilogger) : logger(ilogger) {} void TaskWrapper::loop() { std::string msg(&quot;TaskWrapper::loop: loop is not overridden&quot;); LOG_ERROR(msg); throw std::runtime_error(msg); } void TaskWrapper::startTask(const std::string&amp; iname) { if (task) LOG_INFO(&quot;TaskWrapper::startTask: restarting task: &quot; + iname); task = std::make_unique&lt;CrossplatformThread&gt;(trampoline, this, iname.c_str()); } void TaskWrapper::killTask() { task = nullptr; } std::string TaskWrapper::getName() { return task-&gt;getName(); }; void TaskWrapper::trampoline(void* iparam) { pros::delay(20); static_cast&lt;TaskWrapper*&gt;(iparam)-&gt;loop(); } .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-10-18/task-wrapper/",
    "relUrl": "/2019-10-18/task-wrapper/"
  }
  ,"33": {
    "title": "State Machine",
    "content": "A statemachine is an elegant way of programming a subsystem, and makes it easy to control both in driver control and autonomous. A statemachine is usually implemented using an enum containing a list of states, and then a switch statement in a separate thread that implements each state. . However, implementing a statemachine requires a substantial amount of redundant code to set up the task with setter and getter functions. This is why I wrote an abstract StateMachine wrapper that reduces said boilerplate. StateMachine inherits task functionality from Task Wrapper. . Here is the class, which accepts the enum type as a template parameter: . /** * State machine helper class. * * @tparam States An enum class representing the states of a subsystem. Required to have an * off state. * @tparam assumedState Optional - The assumed last state when using setNewState. Initially calling * setNewState with this state will not trigger a state transition. */ template &lt;typename States, States assumedState = States::off&gt; class StateMachine : public TaskWrapper { public: virtual ~StateMachine() = default; /** * Sets the state. * * @param istate The state */ virtual void setState(const States&amp; istate) { state = istate; } /** * Sets the state and waits until the statemachine reports done. * * @param istate The istate */ virtual void setStateBlocking(const States&amp; istate) { _isDone = false; state = istate; while (!isDone()) { pros::delay(20); }; } /** * Sets the state only if the state is different from the last time this function was called. * * @param istate The state */ virtual void setNewState(const States&amp; istate) { if (istate != lastState) { state = istate; lastState = istate; } } /** * Gets the state. * * @return The state. */ virtual const States&amp; getState() const { return state; } /** * Gets the state. * * @return The state. */ virtual bool isDone() const { return _isDone; } protected: /** * Override this method to implement setup procedures. */ virtual void initialize() = 0; /** * Override this method to implement the statemachine task */ void loop() override = 0; virtual void setDone() { _isDone = true; } States state {States::off}; States lastState {assumedState}; bool _isDone = false; }; .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-10-16/statemachine/",
    "relUrl": "/2019-10-16/statemachine/"
  }
  ,"34": {
    "title": "Motion Algorithms",
    "content": "A big focus for this year has been motion algorithms for autonomous. Motion algorithms allow for a faster, easier, and more competitive autonomous, and are really fun to make. . This year, we have built an X-Drive robot, which opens up a wide range of possibilities for control. Having a holonomic chassis means that we can have heading-agnostic movement functions, meaning that we can drive any direction while facing any angle. This opens up possibilities for turning while driving, and also makes driving to points much easier as the heading of the robot is independent from movement. . Odometry . To be able to execute complex movements that are not straight lines, we need to have a way to track the robot’s position. This both improves accuracy and makes writing algorithms much easier as we can always know the absolute position and angle of the robot in the field. . To do this, we used an odometry algorithm provided by team 5225A. With the use of three freely-spinning tracking wheels, we are able to use trigonometry to calculate the absolute position of the robot in the field. . . A very useful trick we have learned is to calculate the robot’s absolute heading, we can use the following formula: . angleRadians = (leftInch - rightInch) / chassisWidthInch . Motion . Motion algorithms will be a work in progress throughout the year. I will be implementing them in lib7842, so I aim to have good programming practice when making them. I will be starting from last year’s code which will make things easier. . Knowing where the robot is at all times opens up many options. For example, here are some commands we can use to build autonomous programs: . turnToAngle(angle); turnToPoint(point); driveDistance(distance); driveToPoint(point); followPath(path); . Since we have an X-Drive robot, we can often combine driving and turning into a single action, so the turning functions are barely used. . Planning . Since we use odometry and motion algorithms to tell the robot to go to certain coordinates, we can much more easily plan autonomous programs using a map. We overlaid a coordinate system over a top-down view of the field, so we can simply plot and record points: . .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-10-15/motion-algorithms/",
    "relUrl": "/2019-10-15/motion-algorithms/"
  }
  ,"35": {
    "title": "2018-19 Showcase",
    "content": ". Introduction | Who Are We? | Video Explanation/Demo | Flywheel Velocity Control Traditional Control | Custom Algorithm - Feedforward | Accuracy | Signal EMA Filtering | Derivative EMA Filtering | Slew Rate | Flywheel Tuning | V5 Flywheel Datalogging | Flywheel Code | RobotC | PROS (V5) | | Angling Hood Double Ratcheting System | Operation | Angle Request System | Driver Interface/Controller Mapping | Angle Tuning | Code Implementation | | Odometry/Autonomous Odometry Debugging | Movement | PID to heading and distance | Adaptive PID Seeking | Autonomous Code | Settling | Turning | AsyncAction | Emergency Abort | Result | | Vision Sensor Filters and Sorting | EMA Filtering | | 7842 Website | Engineering Journals | Conclusion | Contact | Introduction . Hello everyone! . I’m Theo from 7842F, and I’m the programmer for our team. . I’ve been meaning to make this post ever since worlds, but I haven’t had the time to do so. I now finally have some time before my school starts (I still have 1 week of summer) to show the VEX community our robot and all the different designs we have implemented to make it. . Even though the Turning Point season is way over, the things I will show in this post still applies to this year and VEX in general. . Who Are We? . 7842F is a 2-person team from Vancouver Island, Canada. We meet to build twice a week for ~4 hours, and we design and program at home. We are not allowed to take our robots home, so we try to be as organized and efficient as possible with the time we have to build. Our team captain is Jacob Walter, and he did pretty much all the designing, cadding, building, documentation, journals, and driving. I did all the programming, helped with building, made our website, and was a partner driver at worlds. . Video Explanation/Demo . I recorded a brief video a while ago demonstrating our robot. The following post will cover in more detail the designs that went into each system. . https://www.youtube.com/watch?v=iW4RlnHbDrY . Flywheel Velocity Control . Throughout the TP season, we stuck with a flywheel design. We improved and upgraded it through the year, and gained a lot of knowledge about using it. We went through 3 different flywheel designs. The first was a 1m back-loading simple flywheel, the second a 2m front-loading indexed flywheel, and the last a 2m front loading angling flywheel. . In all our designs, we needed to be able to control the flywheel speed as precisely and consistently as possible. It was also crucial that the flywheel was able to regain its speed as fast as possible after a ball was shot. Since we were using the Cortex system during the development of our flywheel control system, we were able to take advantage of RobotC’s amazing debugger system and graph our flywheel performance. . . Traditional Control . First of all, we tried “traditional” velocity pid control. This is usually what is taught in control theory, and is implemented as output += pid(...);. This means that the motor power being sent to the flywheel is being tweaked incrementally each step by a PID controller. . The issue with this method is that a flywheel is very unresponsive, so the PID would ramp up the motor power much too high, and then the flywheel would overshoot, and then the PID would take a long time to get the flywheel to reach the goal. If we tried to lower the PID gains, the flywheel would be too sluggish and take much too long to react. . This is the velocity PID algorithm used in V5 Motors, OkapiLib, and most velocity PID controllers. . Custom Algorithm - Feedforward . I decided to scrap that algorithm and try to make my own. First, I wanted something that given a target RPM would know right away the general voltage that needed to be sent to the motor. . I did this by introducing a new term named feedforward. Feedforward is simply target * kF, in other words, the higher the target velocity, the proportionally higher the output power. When kF is tuned right, it can bring the flywheel to the approximate ballpark velocity, assuming linear flywheel velocity to input voltage. . For example, if the target is 2800rpm, and kF is tuned for our early-season flywheel, it would output 90 power. This is the term that does most of the grunt work involved with moving the flywheel. . Using feedforward, I could then implement my PID as output = pidf(...); . Accuracy . However, feedforward can’t do all the work. The velocity might not be linear to output power, or there may be some friction or other interference. This is where P (Proportional) comes in. P, supported by F, does the rest of the work by nudging the flywheel power in the right direction to completely reach the goal. For this to work, P must be very high, leading to another problem: oscillation. . The signal coming in from flywheel velocity calculations are quite noisy if you want them to be up-to-date. When the algorithm sees this noise, and kP is high, this translates to noise in the output signal. This means the motor starts oscillating, which translates to real flywheel oscillation. This translates into an even more noisy signal going into the PID, causing a vicious cycle of oscillation. . . Signal EMA Filtering . To solve this issue, the input signal needs to be smoothed. For this, I use an EMA (Exponential Moving Average) filter. . https://en.wikipedia.org/wiki/Moving_average . EMA takes the flywheel reading over time and strikes a balance between taking into account the new reading and keeping the old one. If you overuse EMA, it will cause the signal to be unresponsive and outdated, causing more oscillation, so it is important to use just the right amount to smooth noise. . . Now that EMA causes the input signal to be smooth, the output power will also be steady. This is exactly what we want when controlling a flywheel: smooth, steady power. Now that the input noise and oscillations are damped and filtered out, I can use a large kP gain to be as precise as possible without fearing oscillation. . Note: I could also try to use the I term for more accuracy, but I have not had a good experience with it, as it likes to introduce a lot of oscillations into the system. In my algorithm, I have not implemented I. . Derivative EMA Filtering . When the flywheel shoots a ball, I want the flywheel to recover as quickly as possible, so that the next shot will be consistent. That means I want the motors to spike to full power while the ball is being shot, not once the flywheel has slowed down enough for P to kick in. To do this, I use the D (Derivative) term. D is simply the rate of change of the error, applied to the motors to try to fight against that rate of change. . I don’t just want the D to kick in while the flywheel is slowing down, I also want it to linger a bit after the shot to provide an extra boost. To do this, I also apply an EMA filter on the D. Filtering D is common practice, as it makes D have time to affect the output instead of being there for only a few timeslices. Without filtering, it only acts against the change of motion exactly when it detects it, so in the case of a flywheel, when you shoot a ball, the only effect D will have is exactly when the flywheel is slowing down. With filtering, D lingers a bit after the initial high rate of change. . . As you can see, using a filtered D allows the flywheel to resume target speed as fast as possible. . Slew Rate . Finally, to protect the motors, I apply a one-way slew rate to the output power. This protects the motors during ramp-up and dampens the system. The flywheel power can drop very fast, but it needs to gradually climb back up. . If you look at most of the above graphs, you can see that the initial acceleration of the motor power is gradual. In the following graph, look at how the motor power (green) is limited and ramps up slowly even though the PID would have it at full power instantly. . . Slew rate can be implemented with a simple algorithm. Here is the pseudocode: . increment = output - outputLast; if(abs(increment) &gt; slewLimit) output = outputLast + slewLimit * sgn(increment); outputLast = output; . Flywheel Tuning . To properly tune the flywheel constants, I needed a solution that did not involve redownloading the code every iteration. With RobotC, I could directly tune the constants using the debugger, but with PROS V5, there is no such tool. This is why I designed an LVGL tuning utility. . V1: https://youtu.be/SaY6B3MW3AI . V2: . . I also made a graphing utility to visualize the flywheel performance: . . . V5 Flywheel Datalogging . As you may know, the programming solutions V5 do not have any of the remote debugging features of RobotC. While I did have the GUI graph, I wanted a solution that could record in the background and report to the computer. . Thus I wrote a utility that saved a log of all the flywheel information in a CSV on the SD card. Each time the code ran, it would save a log of the flywheel state. I could then read these files on my computer and import them into graphing software such as R, Excel, or mathplotlib. . I kept this logger running in competitions and even worlds, so if something happened to the flywheel we could go back and look at its log, which contained information like temperature. I recommend using the SD card to store information, as it can be a useful tool. You can also use a third-party library to do the CSV writing and file management for you. . Flywheel Code . I have decided to release the code for this flywheel algorithm! . They are split into 3 parts: . EMA Filter | Velocity PID with D EMA | Implementation with signal EMA and Slew Rate | RobotC . The files are located in . /Libraries/7842FLib/Filter/emaFilter.c | /Libraries/7842FLib/PID/PIDEMASystem.c | /Shared/MainFlywheelTask.c: | https://github.com/theol0403/7842F-Alpha-Code-RobotC . PROS (V5) . https://gist.github.com/theol0403/0b484a5a00274edd5b85aa16009ba1ab . . Angling Hood . For our third robot, the one we took to worlds, we made an angling flywheel hood. It took us months to perfect, but it worked well in the end. . Double Ratcheting System . Our worlds robot had a 2m flywheel. However, we also wanted a 4m base, an intake, an indexer, and an arm. To achieve this, we had to use a motor sharing system. Since the flywheel motors only spin in one direction, we took advantage of the other direction by using a double ratchet system. We could then power another subsystem when the motors spun backward. With this system, we were able to use 2 motors to power our flywheel, indexer, and angler. . We needed smaller and more compact ratchets than was provided by VEX, so Jacob designed a custom ratchet and submitted it to the CAD online challenge: https://challenges.robotevents.com/challenge/94/entry/6325 . . He then expanded that system by making a compact double ratchet. . . The angler is ratcheted so it can only be moved forward. When the angler reaches the maximum position, a slip gear brings the angler back to the resting position. . Operation . Here is the flywheel system’s typical routine: . Both motors spin CCW and work together to spin up the flywheel | When a shooting angle is requested, the angler motor spins CW to engage and move the angler, cycling if needed. The indexer motor maintains the flywheel’s speed. | When the angler is at the desired position, the angler motor resumes powering the flywheel. | When it is time to shoot, the indexer motor spins CW, engaging the indexer and shooting the ball. The angler motor maintains the flywheel’s speed. | The indexer motor resumes powering the flywheel. | If a doubleshot is selected, the angle for the next flag is requested and steps 2-5 repeat | Both motors continue powering the flywheel until the next angle adjustment or shot | Here are a few clips showing the robot doing double shots: . https://youtu.be/l6ZdQ_tHcqg . Angle Request System . The thing that makes our angler different compared to other angling hoods is that we can specify the exact angle we want the ball to shoot. To make the most of this ability, we needed to record the perfect shooting angle for each flag (top and middle) given various shooting positions. . We decided to have 4 shooting positions: . Position 1 is when the angler is all the way back and shoots the top flag | Position 2 is with the back of the robot against the platform | Position 3 is with the front of the robot against the platform | Position 4 is with the back of the robot against the back of the court | If we were on the near starting tile, we could also turn and shoot across the court using angler position 3 and 4. . . Having these positions tuned allowed us to do some pretty cool shots: . . Driver Interface/Controller Mapping . Having all these different shooting configurations required having a dedicated driver setting them. Thus I became the partner driver and controlled the angler. . Our workflow was this: the main driver (Jacob) would grab balls, and then head for any of our 4 shooting positions. He would tell me ahead of time which position he was planning to shoot at. . I would then press the buttons corresponding to that position, so the angler would be at the proper position ahead of time so it could be ready to shoot . After the driver lined up for the shot, I would press the shoot button, which would then execute whatever setting I had specified (top/middle/doubleshot at what position). . Here is our controller mapping: . . I also have a display on the controller that gives me some useful information: . . It tells me which distance and which flag is selected, whether the flywheel is at target velocity, the time left in the match, the robot’s battery, and the controller ID. This display was useful for driving at competitions. A copy of this screen is also on the master controller. . Angle Tuning . To tune the hood angles I experimented with various options. I tried using the controller buttons to tune the angles and writing logs to the SD or the terminal, and making a GUI. They all worked to some extent, but the controller was awkward so I stuck with the GUI option, as it was the most flexible and fast to use. . . The Dist buttons allowed me to control which distance setting to change the angles for, and the Top and Mid buttons allowed me to adjust the angles for that distance. The visualization in the middle of the GUI shows the hood angles - white is the hood’s current angle, and black and blue are the top and mid angles, respectively. . Code Implementation . The angler system was one of the most complicated programs I’ve ever made. It needed to be able to execute a series of dependent actions, but be asynchronous and interruptible. It also needed to be able to manage two other systems (flywheel and indexer) that were independently controlled, delegating motor ownership between them. It also needed to have a clean outside interface for drivercontrol and autonomous. . The solution involved making a statemachine that had a stack containing a list of pending actions. Each action would execute until its conditions were met, and then it would pop itself out of the stack. If an action needed another action to execute, then it would push that action onto the stack. . Here are all the possible actions the angler could take: . enum shootStates { off, //control to flywheel and intake standby, //back position, control to flywheel angling, //indefinite angling cycle, //head to back position extend, //move to extended position waitForSlip, //wait until hood slips waitForRetract, //wait until hood back to 0 pos angleTop, //drop hood to top angle angleMiddle, //drop hood to middle angle angleTopPlatform, //angle top from platform angleMiddlePlatform, //angle middle from platform angleOut, //drop hood to out (ground flag) angle angleTarget, //drop hood to target angle waitForDoubleShot, //if distance is large enough, wait before second shot waitForBall, //wait for ball to be in indexer waitForFlywheel, //wait until flywheel is ready enableShoot, //shoot indexer waitForShoot, //delays until shot detected reportDone, //lets autonomous know loopJob, //reloads current job loopMacro //reloads current macro }; . I then defined a collection of “macros”, groups of actions put together in a sequence: . enum class shootMacros { off, shootTop, shootMiddle, shootBoth, shootTopPlatform, shootMiddlePlatform, shootBothPlatform, shootOut, shootTarget, shoot, angle, cycle }; . Once I had these self-executing macros set up, I could tell the angler statemachine to “shootBoth”, and it would execute these actions: . angleTop | enableShoot | angleMiddle | waitForDoubleShot | enableShoot | reportDone | cycle | standBy | . It was a whole other challenge making the interface between the controller buttons and the statemachine macros, but I won’t get into that in this post. . Our angler system allowed us to shoot from practically anywhere in the court, and at worlds we took advantage of this - the large majority of our shots were taken from behind the platform. It took us a very long time and a lot of work to develop, but it worked very well in the end. . . Odometry/Autonomous . This past year we have developed odometry for our robot. Odometry is the act of tracking the robot’s position in the court and then using that information for autonomous routines. Instead of the standard “drive distance, turn angle”, I can use odometry to say “drive to coordinate, aim at coordinate”. The algorithm for the tracking was generously provided by 5225A, but I developed all the infrastructure and movement algorithms. . We used 2 free-spinning tracking wheels on our robot. Tracking wheels are designed to give the most precision to odometry as possible, as powered wheels can slip and are not as precise. We opted not to use a third tracking wheel because we did not have physical space to put it and we didn’t have any extra sensor ports. If possible I would recommend having a third wheel, as we had some consistency issues/drift because the tracking wheels would sometimes slide sideways. . . Odometry Debugging . Odometry is one of the most difficult things to diagnose if something goes wrong. You don’t know if the wheels failed, if the sensors failed, or if the code is wrong, and in what way. To help alleviate some of that pain, I wrote a GUI utility that helped us pinpoint problems. . . With this, you can try moving the robot in a straight line and see if one sensor is lagging behind the other, or to see if the tracking algorithm is broken. As a tool to help others (and as an incentive to help test OkapLib v4’s beta odometry system), I have published the code for this. . https://github.com/theol0403/odomDebug . Movement . Once you know the position of the robot and where you want to move, the challenge is to actually move there. Here is a basic algorithm to drive to a point: . Calculate angle to target | Turn to face the target | Calculate distance to target | Move distance to reach target | . While this algorithm works decently well, it is quite slow and is not able to dynamically adjust while on-course. I instead wanted to make an algorithm that would curve toward the target, and calculate course adjustments on the fly. . PID to heading and distance . The first algorithm that was tried was PID. The distance and angle to the target would be sent to 2 PID controllers, and then the outputs would be combined. There were two problems with this method. . The first was that the algorithm had to be terminated when the robot reached the general vicinity of the target, or else the robot would start having a spasm. Think about it - PID needs to have a negative input signal to be able to back up and settle. However, when calculating distance to a point (using pythagoras), you can’t know when you overshoot the target. Therefore, the robot can only move forward, so when it reaches and overshoots the target, the angle to the target flips 180 degrees and the distance PID goes full throttle. This causes the robot to go crazy. . The second problem with this method is that it is not the most efficient. If the robot was perpendicular to the target, the distance PID would output full power, even though moving forward is the wrong thing to do. . . Instead, I wanted an algorithm that prioritized turning over moving, and that only moves when doing so would make the robot get nearer to the target. . Adaptive PID Seeking . I posed this question: “If the robot is locked to its current heading, so it can only move forward/backward, how can it move in a straight line to get closest to the point as possible?”. . If the robot was perpendicular to the target, the answer would be 0. But as the robot rotates to face the target, the answer becomes more and more. Here are some images illustrating the question (the answer is the length of the red line): . . With the help of others, I was able to implement the math for this. When doing distance PID on the output of these calculations, the robot was able to move much more efficiently. I also had to implement some logic to be able to drive backward. The reason this algorithm works great for settling is that if I turn off the angle PID when the robot is a certain distance away from the target, the adaptive distance PID brings the robot to a settled stop, giving a negative signal to back up. . To test this algorithm, I (with some help) made a javascript simulation. You can see how the robot prefers turning over driving, and how it settles smoothly. . . Autonomous Code . Once I had the tracking and movement completed, it was time to make an API for me to use for writing autonomous programs. I wanted something flexible, abstract, and feature-packed. Here is what I ended up with: . . Settling . Every single autonomous motion has a settling period. However, I wanted the settling to be customizable for every single command. I wanted to be able to settle a few different ways: . All PID controllers come to a rest | All PID controllers get to some margin of error | The robot gets to a certain requirement, such as a certain distance from a point or a certain angle | . To do this, I created a parameter in each movement function that accepts a function pointer to handle the settling. Every loop, the movement function will ask the settling function “am I settled yet?” and then the function will return true when it’s conditions are met. . Then, I created a few default settling functions and added the functionality to generate new settling functions on the fly. For example, here is a command with a full settle that comes to a stop: chassis.driveToPoint({1_ft, 1_ft}, 1, driveSettle);. If I wanted to make the robot exit the movement when it was 4 inches away from the target, I could say chassis.driveToPoint({1_ft, 1_ft}, 1, makeSettle(4_in));. . Turning . All turning is essentially the same motion. The only difference with all possible turns is the goal calculation and movement method (point, pivot, or arc). To reduce redundancy, I wanted to write only one turning algorithm, and have all the implementations plug-in. Thus I used the same function pointer idea as the settling system and added parameters in the turning function to fulfill the angle calculation and movement method. Here are a few examples of a turn command: . chassis.turn(angleCalc({1_ft, 1_ft}), pointTurn, turnSettle); chassis.turn(angleCalc(90_deg), leftPivot, makeSettle(5_deg)); . For simplicity, I also made a few helper functions - turnToAngle(angle), turnAngle(angle), and turnToPoint(point), which all just call turn(angleCalc) in the backend. . AsyncAction . All the movement functions are blocking, but I still wanted to be able to trigger actions such as moving an arm in the middle of a movement. To do this I developed a system called AsyncAction, which requires a trigger (ex. min distance to point) and executes an action (ex. moves arm). In autonomous, used it to turn on the ball intake right when the robot reached the ball. . . Emergency Abort . There is nothing I dislike more than having the robot slightly off in autonomous, causing it to drive into a wall, and then being stuck there for the rest of the autonomous trying to push the wall over. Thus I made a system that detects when the robot is trying to move but is not moving. When it detects that the robot is stuck, it exits the current movement and goes on to the next one. With odometry, hopefully the robot will be able to continue the autonomous, because it still know its position even though it got stuck and had to abort a movement. . Result . All these abilities made programming autonomous much easier than before. I could use an image of the court to plan my autonomous and simply enter the coordinates of where I want the robot to be. Here are a few videos of our autonomous routines - I know they are not inherently impressive, but we did not have enough time to make many of them. . Notice how the base sometimes curves to get to the target point. . https://www.youtube.com/watch?v=_GutEusmo0g . https://www.youtube.com/watch?v=iPL_i5kivEM . . Vision Sensor . When the VEX Vision sensor came out at the beginning of last year, I was super interested in making an interface for it. I then noticed that the sensor was very unreliable, and the code for interfacing with the objects was quite limited. However, I wanted to use it for aligning with flags, so I set off to try and make the vision sensor better - using programming. . Filters and Sorting . First, I wanted to make filters. I wanted to filter tiny “noise” objects, abnormally sized objects, objects with abnormal proportions, etc. I also wanted to sort objects by arbitrary attributes and have an easy API to do so. This project has been at work all season, I have gone through many versions and it is not completed yet. Here is what my latest version can do: . reader.getAll(); // gets all objects from sensor // remove objects with area smaller than 200 and sort by size // commands can be chained reader.removeWith(objAttr::area, 0, 200).sortBy(objAttr::area); // only keep objects with signature 1 reader.removeWithout(objAttr::sig, 1); . The library can also display objects to the screen for debugging: . https://youtu.be/h7cOevYJF-U . It is likely I will release this library at some point this year when I am happy with it. . EMA Filtering . However, I noticed a problem with the vision sensor. The objects would often flicker and wobble, which I was worried would translate into oscillation and problems with filtering. So I decided that I needed to EMA filter the objects. This is a more difficult task than one would think, as I can’t simply filter by object index because the objects are ordered arbitrarily (or by size, not position). I won’t get into how I managed to do it in this post, but basically, I looked at the objects over time, kept track of where they were, ordered them, and then correlated the objects in a new snapshot with the previous snapshots. I could then EMA filter them. To develop this system, I used the LVGL simulator to test on my computer. If there is interest for me to make a guide on how to set up the simulator with C++, let me know. . I have had an interesting relationship with the vision sensor throughout the season. Despite all the work I did with it, I never got it to the point where I was comfortable using it in competition. It was just so frustrating to use and unreliable. Hopefully, VEX will fix the firmware for the vision sensor and it will become more practical for use. When I have the time I will keep working on my library so that it can be eventually released. . . 7842 Website . Earlier in the season, I designed a website for the online challenges. In hindsight I want to change a lot of things with it and improve the tutorials, but it still stands as a useful resource. I wrote a few tutorials about PROS and programming. Go check it out here! . Engineering Journals . Throughout the season Jacob did an amazing job of documenting our progress. He made two engineering journals, one for project management and ideas, and the other for linear build documentation. If you are interested in our design process, ideas, and more of our robot, check them out! They have earned us awards at every competition we have gone to, except for worlds, because unfortunately there our judging was rushed. However, later we were approached by the pair of judges that we were able to give our full presentation to and were complimented on our presentation. . I hope these journals are a great resource and that they provide a good learning opportunity! My favourite pages are the last 40 of the project journal. . . There are higher and lower-resolution versions, and the original images, available here. Enjoy! . Conclusion . This season has been really fun. Jacob and I have learned a lot and made it to Worlds together for the second time in a row. I have made huge advancements in my programming ability and have found a passion for it. . Unfortunately for me, Jacob has graduated this year and will be going to university. This leaves me as the team captain of a 1-person team with little building skills. Our club leadership has stepped down, leaving the club in a state of uncertainty. I have no idea what will happen in the following season, but I hope I can find a new robotics partner and continue the success of 7842F. . As for programming, I plan to create a library and implement some ideas I have been wanting to make for a while. Stay tuned! . Contact . If anyone has any questions or comments about this post, I am more than happy to answer them. If someone has suggestions to improve this post, let me know while I am still able to edit! . Also, feel free to contact me about programming questions in general on Discord at theol0403#6480. Just know that I will probably tell you to read learncpp.com. . For updates, follow us on our instagram account 7842F_vrc! . . I hope this has provided a valuable resource for future seasons and has taught someone something. Have a great season! .",
    "url": "https://theol0403.github.io/7842B-Journal/2019-08-19/robot-showcase/",
    "relUrl": "/2019-08-19/robot-showcase/"
  }
  
}